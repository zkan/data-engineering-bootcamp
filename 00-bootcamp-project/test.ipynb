{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from google.cloud import bigquery, storage\n",
    "from google.oauth2 import service_account\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data\"\n",
    "BUSINESS_DOMAIN = \"greenery\"\n",
    "location = \"asia-southeast1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyfile = os.environ.get(\"KEYFILE_PATH\")\n",
    "keyfile = \"deb-2023-eb731094ca12-bq&gcs.json\"\n",
    "service_account_info = json.load(open(keyfile))\n",
    "credentials = service_account.Credentials.from_service_account_info(service_account_info)\n",
    "project_id = \"deb-2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Local to GCS\n",
    "bucket_name = \"deb-bootcamp-100018\"\n",
    "storage_client = storage.Client(\n",
    "    project=project_id,\n",
    "    credentials=credentials,\n",
    ")\n",
    "bucket = storage_client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_without_partition(data):\n",
    "    file_path = f\"{DATA_FOLDER}/{data}.csv\"\n",
    "    destination_blob_name = f\"{BUSINESS_DOMAIN}/{data}/{data}.csv\"\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(file_path)\n",
    "\n",
    "# Load data from GCS to BigQuery\n",
    "    bigquery_client = bigquery.Client(\n",
    "        project=project_id,\n",
    "        credentials=credentials,\n",
    "        location=location,\n",
    "    )\n",
    "    table_id = f\"{project_id}.deb_bootcamp.{data}\"\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        skip_leading_rows=1,\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        autodetect=True,\n",
    "    )\n",
    "    job = bigquery_client.load_table_from_uri(\n",
    "        f\"gs://{bucket_name}/{destination_blob_name}\",\n",
    "        table_id,\n",
    "        job_config=job_config,\n",
    "        location=location,\n",
    "    )\n",
    "    job.result()\n",
    "\n",
    "    table = bigquery_client.get_table(table_id)\n",
    "    print(f\"Loaded {table.num_rows} rows and {len(table.schema)} columns to {table_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 150 rows and 5 columns to deb-2023.deb_bootcamp.addresses\n",
      "Loaded 6 rows and 3 columns to deb-2023.deb_bootcamp.promos\n",
      "Loaded 30 rows and 4 columns to deb-2023.deb_bootcamp.products\n",
      "Loaded 862 rows and 3 columns to deb-2023.deb_bootcamp.order_items\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    \"addresses\",\n",
    "    \"promos\",\n",
    "    \"products\",\n",
    "    \"order_items\",\n",
    "]\n",
    "for each in data:\n",
    "    load_data_without_partition(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_partition(data, dt, clustering_fields=[]):\n",
    "    file_path = f\"{DATA_FOLDER}/{data}.csv\"\n",
    "    destination_blob_name = f\"{BUSINESS_DOMAIN}/{data}/{dt}/{data}.csv\"\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(file_path)\n",
    "\n",
    "    # Load data from GCS to BigQuery\n",
    "    bigquery_client = bigquery.Client(\n",
    "        project=project_id,\n",
    "        credentials=credentials,\n",
    "        location=location,\n",
    "    )\n",
    "\n",
    "    partition = dt.replace(\"-\", \"\")\n",
    "    table_id = f\"{project_id}.deb_bootcamp.{data}${partition}\"\n",
    "    if clustering_fields:\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            skip_leading_rows=1,\n",
    "            write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "            source_format=bigquery.SourceFormat.CSV,\n",
    "            autodetect=True,\n",
    "            time_partitioning=bigquery.TimePartitioning(\n",
    "                type_=bigquery.TimePartitioningType.DAY,\n",
    "                field=\"created_at\",\n",
    "            ),\n",
    "            clustering_fields=clustering_fields,\n",
    "        )\n",
    "    else:\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "            skip_leading_rows=1,\n",
    "            write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "            source_format=bigquery.SourceFormat.CSV,\n",
    "            autodetect=True,\n",
    "            time_partitioning=bigquery.TimePartitioning(\n",
    "                type_=bigquery.TimePartitioningType.DAY,\n",
    "                field=\"created_at\",\n",
    "            ),\n",
    "        )\n",
    "    job = bigquery_client.load_table_from_uri(\n",
    "        f\"gs://{bucket_name}/{destination_blob_name}\",\n",
    "        table_id,\n",
    "        job_config=job_config,\n",
    "        location=location,\n",
    "    )\n",
    "    job.result()\n",
    "\n",
    "    table = bigquery_client.get_table(table_id)\n",
    "    print(f\"Loaded {table.num_rows} rows and {len(table.schema)} columns to {table_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1429 rows and 8 columns to deb-2023.deb_bootcamp.events$20210210\n",
      "Loaded 177 rows and 13 columns to deb-2023.deb_bootcamp.orders$20210210\n",
      "Loaded 2 rows and 8 columns to deb-2023.deb_bootcamp.users$20201023\n"
     ]
    }
   ],
   "source": [
    "load_data_with_partition(\"events\", \"2021-02-10\")\n",
    "load_data_with_partition(\"orders\", \"2021-02-10\")\n",
    "load_data_with_partition(\"users\", \"2020-10-23\", [\"first_name\", \"last_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
